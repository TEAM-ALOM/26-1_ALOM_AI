{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATA TARGET ê°’"
      ],
      "metadata": {
        "id": "TR1AwXL8USE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. ë†€ëŒ surprise\n",
        "2. ë‘ë ¤ì›€/ê³µí¬ fear\n",
        "3. í˜ì˜¤ disgust\n",
        "4. í–‰ë³µ happiness\n",
        "5. ìŠ¬í”” sadness\n",
        "6. ë¶„ë…¸ anger\n",
        "7. ë¬´í‘œì •/ì¤‘ë¦½ neutral\n",
        "'''"
      ],
      "metadata": {
        "id": "SLdfffoOQN9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "22e61c9f-d81b-47af-fb06-d0a56b8d7d3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. ë†€ëŒ surprise\\n2. ë‘ë ¤ì›€/ê³µí¬ fear\\n3. í˜ì˜¤ disgust\\n4. í–‰ë³µ happiness\\n5. ìŠ¬í”” sadness\\n6. ë¶„ë…¸ anger\\n7. ë¬´í‘œì •/ì¤‘ë¦½ neutral\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"shuvoalok/raf-db-dataset\")\n",
        "print(\"path:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWntfHq8Psj4",
        "outputId": "9dddfd76-f599-428c-f4f4-4632dd8da256"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'raf-db-dataset' dataset.\n",
            "path: /kaggle/input/raf-db-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATASET ë§í¬\n",
        "[https://www.kaggle.com/datasets/samithsachidanandan/human-face-emotions/data](https://www.kaggle.com/datasets/samithsachidanandan/human-face-emotions/data)"
      ],
      "metadata": {
        "id": "FYdyO3ceUKQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, zipfile\n",
        "import kagglehub\n",
        "\n",
        "# 1) kagglehubë¡œ RAF-DB ë‹¤ìš´ë¡œë“œ (zip or folderë¥¼ ë°›ì„ ìˆ˜ ìˆìŒ)\n",
        "path = kagglehub.dataset_download(\"shuvoalok/raf-db-dataset\")\n",
        "print(\"kagglehub path:\", path)\n",
        "print(\"list(path):\", os.listdir(path)[:20])\n",
        "\n",
        "# 2) path ì•ˆ/ì£¼ë³€ì—ì„œ zipì„ ì°¾ê±°ë‚˜, ì´ë¯¸ DATASETì´ í’€ë ¤ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "def find_dataset_root(p):\n",
        "    # ì¼€ì´ìŠ¤ A: ì´ë¯¸ DATASET í´ë”ê°€ ë°”ë¡œ ìˆìŒ\n",
        "    if os.path.isdir(os.path.join(p, \"DATASET\")):\n",
        "        return p\n",
        "\n",
        "    # ì¼€ì´ìŠ¤ B: p ìì²´ê°€ DATASETì¼ ìˆ˜ë„ ìˆìŒ\n",
        "    if os.path.basename(p) == \"DATASET\" and os.path.isdir(os.path.join(p, \"train\")):\n",
        "        return os.path.dirname(p)\n",
        "\n",
        "    # ì¼€ì´ìŠ¤ C: zipì´ ìˆìœ¼ë©´ /content/rafdb_extracted ë¡œ í’€ê¸°\n",
        "    zips = glob.glob(os.path.join(p, \"*.zip\"))\n",
        "    if not zips:\n",
        "        # ìƒìœ„ì—ë„ zipì´ ìˆì„ ìˆ˜ ìˆì–´ í•œ ë‹¨ê³„ ë” íƒìƒ‰\n",
        "        zips = glob.glob(os.path.join(os.path.dirname(p), \"*.zip\"))\n",
        "\n",
        "    if zips:\n",
        "        zpath = zips[0]\n",
        "        out_dir = \"/content/rafdb_extracted\"\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(zpath, \"r\") as z:\n",
        "            z.extractall(out_dir)\n",
        "\n",
        "        # extract í›„ DATASET ì°¾ê¸°\n",
        "        for root, dirs, files in os.walk(out_dir):\n",
        "            if \"DATASET\" in dirs:\n",
        "                return os.path.join(root)\n",
        "    return None\n",
        "\n",
        "dataset_root = find_dataset_root(path)\n",
        "print(\"dataset_root:\", dataset_root)\n",
        "\n",
        "# 3) ìµœì¢… BASE_DIR í™•ì • (ì›ë˜ ì½”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” ìœ„ì¹˜)\n",
        "BASE_DIR = os.path.join(dataset_root, \"DATASET\")\n",
        "TRAIN_ROOT = os.path.join(BASE_DIR, \"train\")\n",
        "TEST_ROOT  = os.path.join(BASE_DIR, \"test\")\n",
        "\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "print(\"train exists?\", os.path.exists(TRAIN_ROOT))\n",
        "print(\"test exists?\", os.path.exists(TEST_ROOT))\n",
        "print(\"train subdirs:\", os.listdir(TRAIN_ROOT)[:10])  # 1~7 ë‚˜ì™€ì•¼ ì •ìƒ\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhgei_tebU8z",
        "outputId": "37523ba0-f7b7-4953-a17c-6029f239aaa5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'raf-db-dataset' dataset.\n",
            "kagglehub path: /kaggle/input/raf-db-dataset\n",
            "list(path): ['test_labels.csv', 'DATASET', 'train_labels.csv']\n",
            "dataset_root: /kaggle/input/raf-db-dataset\n",
            "BASE_DIR: /kaggle/input/raf-db-dataset/DATASET\n",
            "train exists? True\n",
            "test exists? True\n",
            "train subdirs: ['7', '2', '5', '3', '1', '4', '6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9z8Cfr5c6_x",
        "outputId": "9bd7466a-21a5-4195-d3da-452cb92d96d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (26.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cpu)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchinfo\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torch.optim import Adam\n",
        "import torchmetrics\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import albumentations as A\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "8aKBPSXZcITa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# BASE_DIR ì˜ˆ: /kaggle/input/raf-db-dataset/DATASET\n",
        "TRAIN_ROOT = os.path.join(BASE_DIR, \"train\")\n",
        "TEST_ROOT  = os.path.join(BASE_DIR, \"test\")\n",
        "\n",
        "def build_df(root_dir):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # root_dir ì•„ë˜ì— 1~7 í´ë”ê°€ ìˆìŒ\n",
        "    for label_str in sorted(os.listdir(root_dir)):  # '1'~'7'\n",
        "        class_dir = os.path.join(root_dir, label_str)\n",
        "        if not os.path.isdir(class_dir):\n",
        "            continue\n",
        "\n",
        "        label = int(label_str)  # âœ… í´ë”ëª…ì´ ë¼ë²¨(1~7)\n",
        "\n",
        "        for fname in os.listdir(class_dir):\n",
        "            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                image_paths.append(os.path.join(class_dir, fname))\n",
        "                labels.append(label)\n",
        "\n",
        "    return pd.DataFrame({\"image_path\": image_paths, \"label\": labels})\n",
        "\n",
        "train_df_full = build_df(TRAIN_ROOT)\n",
        "test_df       = build_df(TEST_ROOT)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df_full,\n",
        "    test_size=0.2,\n",
        "    stratify=train_df_full[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"train/val/test:\", train_df.shape, val_df.shape, test_df.shape)\n",
        "print(\"train label counts:\\n\", train_df[\"label\"].value_counts().sort_index())\n",
        "\n",
        "# âœ… ê²½ë¡œ ì¡´ì¬ í™•ì¸(True ë– ì•¼ ì •ìƒ)\n",
        "print(\"sample train path:\", train_df.iloc[0][\"image_path\"])\n",
        "print(\"exists?\", os.path.exists(train_df.iloc[0][\"image_path\"]))"
      ],
      "metadata": {
        "id": "yjEDnRQNTW9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1016bb2b-430b-4846-b280-d4a3f35c003e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/val/test: (9816, 2) (2455, 2) (3068, 2)\n",
            "train label counts:\n",
            " label\n",
            "1    1032\n",
            "2     225\n",
            "3     574\n",
            "4    3817\n",
            "5    1585\n",
            "6     564\n",
            "7    2019\n",
            "Name: count, dtype: int64\n",
            "sample train path: /kaggle/input/raf-db-dataset/DATASET/train/4/train_08289_aligned.jpg\n",
            "exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì±„í™˜\n",
        "ë°ì´í„° ê°€ê³µ ë° Dataset & DataLoader ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "yEXJ5EsJXAG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "IpnwH_Y6aqCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# CNN Dataset\n",
        "class Custom_Dataset(Dataset):\n",
        "    # ì—¬ê¸°ì„œ transformì€ albumentations transformì´ë¼ê³  ê°€ì •.\n",
        "    # ëª¨ë“  imageëŠ” OpenCVë¡œ ë‹¤ë£¸.\n",
        "    # ë”°ë¼ì„œ ë§ˆì§€ë§‰ì— last channel -> first channelë¡œ ë°”ê¿”ì£¼ëŠ” ë¡œì§ì´ ë³„ë„ë¡œ í•„ìš”.\n",
        "    def __init__(self, image_paths, targets=None, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    # ì „ì²´ ê±´ìˆ˜ ë°˜í™˜\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    # ì£¼ìš” ë©”ì»¤ë‹ˆì¦˜\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        # imageëŠ” ndarry.\n",
        "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # albumentation ë³„ë„ ì ìš©.\n",
        "        # albumentationì—ì„œ ToTensorV2ë¥¼ ë³„ë„ë¡œ ì ìš©.\n",
        "        # ì‚¬ì‹¤ ì´ ë¡œì§ì´ ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ.\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)['image']\n",
        "\n",
        "        if self.targets is not None:\n",
        "            target = torch.tensor(self.targets[idx])\n",
        "            return image, target\n",
        "        else:\n",
        "            return image"
      ],
      "metadata": {
        "id": "bU_BdArYaqAV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    #A.VerticalFlip(p=0.5),\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2(),\n",
        "])"
      ],
      "metadata": {
        "id": "91M7noB2ap-R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Custom_Dataset(train_df['image_path'].values, train_df['label'].values, transform=train_transform)\n",
        "val_dataset = Custom_Dataset(val_df['image_path'].values, val_df['label'].values, transform=val_transform)\n",
        "test_dataset = Custom_Dataset(test_df['image_path'].values, test_df['label'].values, transform=test_transform)"
      ],
      "metadata": {
        "id": "n5v0cvx5ap8p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "mH-DcNd6ap6P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None # ì´ ì¤„ì€ ì´ì „ì— SyntaxErrorë¥¼ ë°œìƒì‹œì¼°ìŠµë‹ˆë‹¤. ë¬¸ë²• ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Noneìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "ktWkFku6c22Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pretrained_model(model_name='alexnet', classifier_layer=None, image_size=[224, 224], make_summary=False):\n",
        "    if model_name == 'alexnet':\n",
        "        model = models.alexnet(weights='DEFAULT')\n",
        "        model.classifier = classifier_layer\n",
        "    elif model_name == 'resnet50':\n",
        "        model = models.resnet50(weights='DEFAULT')\n",
        "        model.fc = classifier_layer\n",
        "    elif model_name == 'resnet101':\n",
        "        model = models.resnet101(weights='DEFAULT')\n",
        "        model.fc = classifier_layer\n",
        "    elif model_name == 'efficientnet_b0':\n",
        "        model = models.efficientnet_b0(weights='DEFAULT')\n",
        "        model.classifier = classifier_layer\n",
        "    elif model_name == 'efficientnet_b4':\n",
        "        model = models.efficientnet_b4(weights='DEFAULT')\n",
        "        model.classifier = classifier_layer\n",
        "    elif model_name == 'efficientnet_v2_s':\n",
        "        model = models.efficientnet_v2_s(weights='DEFAULT')\n",
        "        model.classifier = classifier_layer\n",
        "    elif model_name == 'efficientnet_v2_m':\n",
        "        model = models.efficientnet_v2_m(weights='DEFAULT')\n",
        "        model.classifier = classifier_layer\n",
        "    elif model_name == 'efficientnet_v2_l':\n",
        "        model = models.efficientnet_v2_l(weights='DEFAULT')\n",
        "        model.classifier = classifier_layer\n",
        "    elif model_name == 'convnext_base':\n",
        "        model = models.convnext_base(weights='DEFAULT')\n",
        "        model.classifier[2] = classifier_layer\n",
        "    elif model_name == 'convnext_small':\n",
        "        model = models.convnext_small(weights='DEFAULT')\n",
        "        model.classifier[2] = classifier_layer\n",
        "    else:\n",
        "        print(\"ğŸ§¨ğŸ§¨ [ERROR] ëª¨ë¸ ì´ë¦„ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ğŸ§¨ğŸ§¨\")\n",
        "        return None\n",
        "\n",
        "    if make_summary:\n",
        "        # ëª¨ë¸ ì •ë³´ ìš”ì•½(model summary)\n",
        "        print(torchinfo.summary(model, input_size=[1, 3] + image_size,\n",
        "                  col_names=['output_size', 'num_params', 'trainable'],\n",
        "                  row_settings=['depth', 'var_names'],\n",
        "                  depth=3))\n",
        "\n",
        "    return model\n",
        "\n",
        "classifier_layer = nn.Sequential(\n",
        "    nn.Linear(in_features=1280, out_features=2),\n",
        ")\n",
        "\n",
        "eff_model = create_pretrained_model(\n",
        "    model_name = 'efficientnet_b0',\n",
        "    classifier_layer = classifier_layer,\n",
        "    make_summary=True\n",
        "    )"
      ],
      "metadata": {
        "id": "S6q-dYEIc2v0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6752e132-fad9-48c1-8e66-76123168f7e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================================================================\n",
            "Layer (type (var_name):depth-idx)                                 Output Shape              Param #                   Trainable\n",
            "============================================================================================================================================\n",
            "EfficientNet (EfficientNet)                                       [1, 2]                    --                        True\n",
            "â”œâ”€Sequential (features): 1-1                                      [1, 1280, 7, 7]           --                        True\n",
            "â”‚    â””â”€Conv2dNormActivation (0): 2-1                              [1, 32, 112, 112]         --                        True\n",
            "â”‚    â”‚    â””â”€Conv2d (0): 3-1                                       [1, 32, 112, 112]         864                       True\n",
            "â”‚    â”‚    â””â”€BatchNorm2d (1): 3-2                                  [1, 32, 112, 112]         64                        True\n",
            "â”‚    â”‚    â””â”€SiLU (2): 3-3                                         [1, 32, 112, 112]         --                        --\n",
            "â”‚    â””â”€Sequential (1): 2-2                                        [1, 16, 112, 112]         --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-4                                       [1, 16, 112, 112]         1,448                     True\n",
            "â”‚    â””â”€Sequential (2): 2-3                                        [1, 24, 56, 56]           --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-5                                       [1, 24, 56, 56]           6,004                     True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-6                                       [1, 24, 56, 56]           10,710                    True\n",
            "â”‚    â””â”€Sequential (3): 2-4                                        [1, 40, 28, 28]           --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-7                                       [1, 40, 28, 28]           15,350                    True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-8                                       [1, 40, 28, 28]           31,290                    True\n",
            "â”‚    â””â”€Sequential (4): 2-5                                        [1, 80, 14, 14]           --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-9                                       [1, 80, 14, 14]           37,130                    True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-10                                      [1, 80, 14, 14]           102,900                   True\n",
            "â”‚    â”‚    â””â”€MBConv (2): 3-11                                      [1, 80, 14, 14]           102,900                   True\n",
            "â”‚    â””â”€Sequential (5): 2-6                                        [1, 112, 14, 14]          --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-12                                      [1, 112, 14, 14]          126,004                   True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-13                                      [1, 112, 14, 14]          208,572                   True\n",
            "â”‚    â”‚    â””â”€MBConv (2): 3-14                                      [1, 112, 14, 14]          208,572                   True\n",
            "â”‚    â””â”€Sequential (6): 2-7                                        [1, 192, 7, 7]            --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-15                                      [1, 192, 7, 7]            262,492                   True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-16                                      [1, 192, 7, 7]            587,952                   True\n",
            "â”‚    â”‚    â””â”€MBConv (2): 3-17                                      [1, 192, 7, 7]            587,952                   True\n",
            "â”‚    â”‚    â””â”€MBConv (3): 3-18                                      [1, 192, 7, 7]            587,952                   True\n",
            "â”‚    â””â”€Sequential (7): 2-8                                        [1, 320, 7, 7]            --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-19                                      [1, 320, 7, 7]            717,232                   True\n",
            "â”‚    â””â”€Conv2dNormActivation (8): 2-9                              [1, 1280, 7, 7]           --                        True\n",
            "â”‚    â”‚    â””â”€Conv2d (0): 3-20                                      [1, 1280, 7, 7]           409,600                   True\n",
            "â”‚    â”‚    â””â”€BatchNorm2d (1): 3-21                                 [1, 1280, 7, 7]           2,560                     True\n",
            "â”‚    â”‚    â””â”€SiLU (2): 3-22                                        [1, 1280, 7, 7]           --                        --\n",
            "â”œâ”€AdaptiveAvgPool2d (avgpool): 1-2                                [1, 1280, 1, 1]           --                        --\n",
            "â”œâ”€Sequential (classifier): 1-3                                    [1, 2]                    --                        True\n",
            "â”‚    â””â”€Linear (0): 2-10                                           [1, 2]                    2,562                     True\n",
            "============================================================================================================================================\n",
            "Total params: 4,010,110\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 384.59\n",
            "============================================================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 107.88\n",
            "Params size (MB): 16.04\n",
            "Estimated Total Size (MB): 124.52\n",
            "============================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VQBzZT4-czjG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1eP6fNAczhH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì„œí˜„\n",
        "ëª¨ë¸ í•™ìŠµ ë¡œì§ ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "Xwdg6yhLXCJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN í•™ìŠµ Class\n",
        "class Trainer:\n",
        "  def __init__(self, model=None, train_dataloader=None, val_dataloader=None, loss_fn=None, auc_metric=None, acc_metric=None, optimizer=None, scheduler=None):\n",
        "    self.model = model\n",
        "    self.val_dataloader = val_dataloader\n",
        "    self.loss_fn = loss_fn    # ì†ì‹¤ í•¨ìˆ˜\n",
        "    self.auc_metric = auc_metric    # í‰ê°€ ì§€í‘œ: AUC\n",
        "    self.acc_metric = acc_metric    # í‰ê°€ ì§€í‘œ: ì •í™•ë„ (Accuracy)\n",
        "    self.optimizer = optimizer    # ìµœì í™” ë„êµ¬\n",
        "    self.scheduler = scheduler    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
        "\n",
        "    # ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
        "    self.best_val_f1 = 0.0    # ìµœê³  ì ìˆ˜ë¥¼ ì €ì¥í•  ë³€ìˆ˜\n",
        "    self.best_model_state = None    # ìµœê³  ì ìˆ˜ì¼ ë•Œì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•  ë³€ìˆ˜\n",
        "\n",
        "  # 1ë²ˆ ì—í¬í¬ í•™ìŠµ í•¨ìˆ˜\n",
        "  def train_epoch(self, train_dataloader):\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # ëª¨ë¸ê³¼ í‰ê°€ ì§€í‘œë“¤ì„ í•´ë‹¹ ì¥ì¹˜(GPU/CPU)ë¡œ ì´ë™\n",
        "    self.model = self.model.to(device)\n",
        "    if self.acc_metric is not None:\n",
        "      self.acc_metric = self.acc_metric.to(device)\n",
        "    if self.auc_metric is not None:\n",
        "      self.auc_metric = self.auc_metric.to(device)\n",
        "\n",
        "    # ì—í¬í¬ ë™ì•ˆì˜ í‰ê·  ì†ì‹¤(Loss)ì„ ê³„ì‚°í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
        "    avg_loss = 0\n",
        "    sum_loss = 0\n",
        "\n",
        "    # ëª¨ë¸ í•™ìŠµ ì„¤ì •\n",
        "    self.model.train()\n",
        "\n",
        "    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ë¥  ë°”(progress bar) ìƒì„±\n",
        "    with tqdm(total = len(train_dataloader), desc=\"[Training...]\", leave=True) as progress_bar:\n",
        "      for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # ë¼ë²¨ ë³´ì •\n",
        "        labels = labels - 1\n",
        "\n",
        "\n",
        "        # ìˆœì „íŒŒ (Forward Pass): ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì˜ˆì¸¡ê°’(logits)ì„ ë‚´ë†“ìŒ\n",
        "        logits = self.model(images)\n",
        "\n",
        "        # ì†ì‹¤ ê³„ì‚°: ì˜ˆì¸¡ê°’(logits)ê³¼ ì •ë‹µ(labels)ì˜ ì°¨ì´(Loss)ë¥¼ ê³„ì‚°\n",
        "        loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        # ì†ì‹¤ ê¸°ë¡: í˜„ì¬ ë°°ì¹˜ì˜ ì†ì‹¤ì„ ëˆ„ì í•˜ê³  í‰ê· ì„ ê³„ì‚°\n",
        "        sum_loss += loss.item()\n",
        "        avg_loss = sum_loss / (batch_idx + 1)\n",
        "\n",
        "        # í‰ê°€ ì§€í‘œ ì—…ë°ì´íŠ¸\n",
        "        if self.auc_metric is not None:\n",
        "          self.auc_metric.update(F.softmax(logits, dim=-1), labels)\n",
        "        if self.acc_metric is not None:\n",
        "          self.acc_metric.update(F.softmax(logits, dim=-1).argmax(dim=-1), labels)\n",
        "\n",
        "        # ì—­ì „íŒŒ\n",
        "        self.optimizer.zero_grad()    # ì´ì „ ë°°ì¹˜ì˜ ê¸°ìš¸ê¸°(gradient) ì´ˆê¸°í™”\n",
        "        loss.backward()    # í˜„ì¬ ì˜¤ì°¨ì— ëŒ€í•œ ê¸°ìš¸ê¸° ê³„ì‚° (ì—­ì „íŒŒ)\n",
        "        self.optimizer.step()    # ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ì´ìš©í•´ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
        "\n",
        "        # ì§„í–‰ë¥  ë°” 1ì¹¸ ì¦ê°€\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        # 20ë²ˆì§¸ ë°°ì¹˜ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ë°°ì¹˜ì¼ ë•Œ í˜„ì¬ ìƒíƒœ ì¶œë ¥\n",
        "        if batch_idx % 20 == 0 or batch_idx+1 == len(train_dataloader):\n",
        "          current_auc = self.auc_metric.compute().item() if self.auc_metric is not None else 0.0\n",
        "          current_acc = self.acc_metric.compute().item() if self.acc_metric is not None else 0.0\n",
        "\n",
        "          progress_bar.set_postfix({\n",
        "            \"Train_Loss\": avg_loss,\n",
        "            \"Train_ACC\": current_acc,\n",
        "            \"Train_AUC\": current_auc,\n",
        "          })\n",
        "\n",
        "      if self.auc_metric is not None:\n",
        "        self.auc_metric.reset()\n",
        "      if self.acc_metric is not None:\n",
        "        self.acc_metric.reset()\n",
        "\n",
        "    return avg_loss, current_acc, current_auc\n",
        "\n",
        "  # 1ë²ˆ ì—í¬í¬ ê²€ì¦ í•¨ìˆ˜\n",
        "  def validate_epoch(self, val_dataloader):\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    self.model = self.model.to(device)\n",
        "    if self.acc_metric is not None:\n",
        "      self.acc_metric = self.acc_metric.to(device)\n",
        "    if self.auc_metric is not None:\n",
        "      self.auc_metric = self.auc_metric.to(device)\n",
        "\n",
        "    # í‰ê·  lossë¥¼ êµ¬í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
        "    avg_loss = 0\n",
        "    sum_loss = 0\n",
        "\n",
        "    # ëª¨ë¸ í‰ê°€ë¡œ ì„¤ì •\n",
        "    self.model.eval()\n",
        "\n",
        "    # ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”\n",
        "    with torch.no_grad():\n",
        "      with tqdm(total = len(val_dataloader), desc=\"[Validating..]\", leave=True) as progress_bar:\n",
        "        for batch_idx, (images, labels) in enumerate(val_dataloader):\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # ë¼ë²¨ ë³´ì •\n",
        "          labels = labels - 1\n",
        "\n",
        "          logits = self.model(images)\n",
        "          loss = self.loss_fn(logits, labels)\n",
        "          sum_loss += loss.item()\n",
        "          avg_loss = sum_loss / (batch_idx + 1)\n",
        "\n",
        "          if self.auc_metric is not None:\n",
        "            self.auc_metric.update(F.softmax(logits, dim=-1), labels)\n",
        "          if self.acc_metric is not None:\n",
        "            self.acc_metric.update(F.softmax(logits, dim=-1).argmax(dim=-1), labels)\n",
        "\n",
        "          # ì§„í–‰ë¥  ë°” ì—…ë°ì´íŠ¸\n",
        "          progress_bar.update(1)\n",
        "\n",
        "          if batch_idx % 20 == 0 or batch_idx + 1 == len(val_dataloader):\n",
        "            current_acc = self.acc_metric.compute().item() if self.acc_metric is not None else 0.0\n",
        "            current_auc = self.auc_metric.compute().item() if self.auc_metric is not None else 0.0\n",
        "            progress_bar.set_postfix({\n",
        "              \"Validate_Loss\": avg_loss,\n",
        "              \"Validate_ACC\": current_acc,\n",
        "              \"Validate_AUC\": current_auc,\n",
        "            })\n",
        "\n",
        "        if self.acc_metric is not None:\n",
        "          self.acc_metric.reset()\n",
        "        if self.auc_metric is not None:\n",
        "          self.auc_metric.reset()\n",
        "\n",
        "    return avg_loss, current_acc, current_auc\n",
        "\n",
        "\n",
        "  # fit í•¨ìˆ˜: ì „ì²´ í•¨ìˆ˜ ë£¨í”„ ê´€ë¦¬\n",
        "  def fit(self, epochs, train_dataloader=None, val_dataloader=None):\n",
        "    # í•™ìŠµ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
        "    history = {\n",
        "      'train_loss' : [], 'val_loss' : [],\n",
        "      'train_acc' : [], 'val_acc' : [],\n",
        "      'train_auc' : [], 'val_auc' : [],\n",
        "    }\n",
        "\n",
        "    print(\"ëª¨ë¸ í•™ìŠµ ì‹œì‘!\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "      print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "      print(\"-\" * 30)\n",
        "\n",
        "      # í•™ìŠµ ì‹¤í–‰\n",
        "      if train_dataloader is not None:\n",
        "        train_loss, train_acc, train_auc = self.train_epoch(train_dataloader)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['train_auc'].append(train_auc)\n",
        "      else:\n",
        "        print(\"í•™ìŠµ ë°ì´í„°ë¡œë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ!\")\n",
        "        return history\n",
        "\n",
        "      # ê²€ì¦ ì‹¤í–‰\n",
        "      if val_dataloader is not None:\n",
        "        val_loss, val_acc, val_auc = self.validate_epoch(val_dataloader)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_auc'].append(val_auc)\n",
        "\n",
        "        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
        "        if self.scheduler is not None:\n",
        "          self.scheduler.step(val_loss)\n",
        "\n",
        "        # ìµœê³  ëª¨ë¸ ì €ì¥\n",
        "        if val_acc > self.best_val_f1:\n",
        "          self.best_val_f1 = val_acc\n",
        "          self.best_model_state = self.model.state_dict().copy()\n",
        "          print(f\"ìƒˆë¡œìš´ ìµœê³  ACC ì ìˆ˜: {self.best_val_f1:.4f}\")\n",
        "\n",
        "      # ê²°ê³¼ ì¶œë ¥\n",
        "      print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train AUC: {train_auc:.4f}\")\n",
        "      if val_dataloader is not None:\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}\")\n",
        "        if self.scheduler is not None:\n",
        "          print(f\"Learning Rate: {self.optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    # ìµœê³  ëª¨ë¸ ë³µì›\n",
        "    if self.best_model_state is not None:\n",
        "      self.model.load_state_dict(self.best_model_state)\n",
        "      print(f\"ìµœê³  ACC ì ìˆ˜ ëª¨ë¸ë¡œ ë³µì› ì™„ë£Œ: {self.best_val_f1:.4f}\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "  # ëª¨ë¸ í‰ê°€\n",
        "  def evaluate(self, eval_dataloader):\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    self.model = self.model.to(device)\n",
        "    if self.acc_metric is not None:\n",
        "      self.acc_metric = self.acc_metric.to(device)\n",
        "    if self.auc_metric is not None:\n",
        "      self.auc_metric = self.auc_metric.to(device)\n",
        "\n",
        "    # í‰ê·  lossë¥¼ êµ¬í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
        "    avg_loss = 0\n",
        "    sum_loss = 0\n",
        "\n",
        "    # ëª¨ë¸ í‰ê°€ë¡œ ì„¤ì •\n",
        "    self.model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      with tqdm(total = len(eval_dataloader), desc=\"[Evaluating..]\", leave=True) as progress_bar:\n",
        "        for batch_idx, (images, labels) in enumerate(eval_dataloader):\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # ë¼ë²¨ ë³´ì •\n",
        "          labels = labels -1\n",
        "\n",
        "          logits = self.model(images)\n",
        "          loss = self.loss_fn(logits, labels)\n",
        "          sum_loss += loss.item()\n",
        "          avg_loss = sum_loss / (batch_idx+1)\n",
        "\n",
        "          if self.auc_metric is not None:\n",
        "            self.auc_metric.update(F.softmax(logits, dim=-1), labels)\n",
        "          if self.acc_metric is not None:\n",
        "            self.acc_metric.update(F.softmax(logits, dim=-1).argmax(dim=-1), labels)\n",
        "\n",
        "          # ì§„í–‰ë¥  ë°” ì—…ë°ì´íŠ¸\n",
        "          progress_bar.update(1)\n",
        "\n",
        "          if batch_idx % 20 == 0 or batch_idx + 1 == len(eval_dataloader):\n",
        "            current_acc = self.acc_metric.compute().item() if self.acc_metric is not None else 0.0\n",
        "            current_auc = self.auc_metric.compute().item() if self.auc_metric is not None else 0.0\n",
        "            progress_bar.set_postfix({\n",
        "              \"Evaluate_Loss\": avg_loss,\n",
        "              \"Evaluate_ACC\": current_acc,\n",
        "              \"Evaluate_AUC\": current_auc,\n",
        "            })\n",
        "\n",
        "        if self.acc_metric is not None:\n",
        "          self.acc_metric.reset()\n",
        "        if self.auc_metric is not None:\n",
        "          self.auc_metric.reset()\n",
        "\n",
        "    return avg_loss, current_acc, current_auc\n",
        "\n",
        "  # ë§ˆì§€ë§‰ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ ë°˜í™˜\n",
        "  def get_trained_model(self):\n",
        "    return self.model"
      ],
      "metadata": {
        "id": "U1oHhTlOXE8D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# í•™ìŠµì„ ìœ„í•œ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
        "\n",
        "\n",
        "# 7ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë¶„ë¥˜ê¸° ë ˆì´ì–´\n",
        "classifier_layer = nn.Sequential(\n",
        "  nn.Dropout(0.5),\n",
        "  nn.Linear(in_features=1280, out_features=512),\n",
        "  nn.ReLU(),\n",
        "  nn.Dropout(0.3),\n",
        "  nn.Linear(in_features=512, out_features=7)\n",
        ")\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "model = create_pretrained_model(\n",
        "  model_name = 'efficientnet_b0',\n",
        "  classifier_layer = classifier_layer,\n",
        "  make_summary=True\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# í•™ìŠµ ì„¤ì •\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
        "\n",
        "# í‰ê°€ ì§€í‘œ ì„¤ì •\n",
        "auc_metric = torchmetrics.AUROC(task=\"multiclass\", num_classes=7)\n",
        "acc_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=7)\n",
        "\n",
        "# Trainer í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ë°ì´í„° ì£¼ì…\n",
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  train_dataloader=train_dataloader,\n",
        "  val_dataloader=val_dataloader,\n",
        "  loss_fn=loss_fn,\n",
        "  auc_metric=auc_metric,\n",
        "  acc_metric=acc_metric,\n",
        "  optimizer=optimizer,\n",
        "  scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "id": "tusSvXQVXE6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e193c30-6c14-4076-9d7b-e5b0992b5efa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì‚¬ìš© ë””ë°”ì´ìŠ¤: cpu\n",
            "============================================================================================================================================\n",
            "Layer (type (var_name):depth-idx)                                 Output Shape              Param #                   Trainable\n",
            "============================================================================================================================================\n",
            "EfficientNet (EfficientNet)                                       [1, 7]                    --                        True\n",
            "â”œâ”€Sequential (features): 1-1                                      [1, 1280, 7, 7]           --                        True\n",
            "â”‚    â””â”€Conv2dNormActivation (0): 2-1                              [1, 32, 112, 112]         --                        True\n",
            "â”‚    â”‚    â””â”€Conv2d (0): 3-1                                       [1, 32, 112, 112]         864                       True\n",
            "â”‚    â”‚    â””â”€BatchNorm2d (1): 3-2                                  [1, 32, 112, 112]         64                        True\n",
            "â”‚    â”‚    â””â”€SiLU (2): 3-3                                         [1, 32, 112, 112]         --                        --\n",
            "â”‚    â””â”€Sequential (1): 2-2                                        [1, 16, 112, 112]         --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-4                                       [1, 16, 112, 112]         1,448                     True\n",
            "â”‚    â””â”€Sequential (2): 2-3                                        [1, 24, 56, 56]           --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-5                                       [1, 24, 56, 56]           6,004                     True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-6                                       [1, 24, 56, 56]           10,710                    True\n",
            "â”‚    â””â”€Sequential (3): 2-4                                        [1, 40, 28, 28]           --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-7                                       [1, 40, 28, 28]           15,350                    True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-8                                       [1, 40, 28, 28]           31,290                    True\n",
            "â”‚    â””â”€Sequential (4): 2-5                                        [1, 80, 14, 14]           --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-9                                       [1, 80, 14, 14]           37,130                    True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-10                                      [1, 80, 14, 14]           102,900                   True\n",
            "â”‚    â”‚    â””â”€MBConv (2): 3-11                                      [1, 80, 14, 14]           102,900                   True\n",
            "â”‚    â””â”€Sequential (5): 2-6                                        [1, 112, 14, 14]          --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-12                                      [1, 112, 14, 14]          126,004                   True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-13                                      [1, 112, 14, 14]          208,572                   True\n",
            "â”‚    â”‚    â””â”€MBConv (2): 3-14                                      [1, 112, 14, 14]          208,572                   True\n",
            "â”‚    â””â”€Sequential (6): 2-7                                        [1, 192, 7, 7]            --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-15                                      [1, 192, 7, 7]            262,492                   True\n",
            "â”‚    â”‚    â””â”€MBConv (1): 3-16                                      [1, 192, 7, 7]            587,952                   True\n",
            "â”‚    â”‚    â””â”€MBConv (2): 3-17                                      [1, 192, 7, 7]            587,952                   True\n",
            "â”‚    â”‚    â””â”€MBConv (3): 3-18                                      [1, 192, 7, 7]            587,952                   True\n",
            "â”‚    â””â”€Sequential (7): 2-8                                        [1, 320, 7, 7]            --                        True\n",
            "â”‚    â”‚    â””â”€MBConv (0): 3-19                                      [1, 320, 7, 7]            717,232                   True\n",
            "â”‚    â””â”€Conv2dNormActivation (8): 2-9                              [1, 1280, 7, 7]           --                        True\n",
            "â”‚    â”‚    â””â”€Conv2d (0): 3-20                                      [1, 1280, 7, 7]           409,600                   True\n",
            "â”‚    â”‚    â””â”€BatchNorm2d (1): 3-21                                 [1, 1280, 7, 7]           2,560                     True\n",
            "â”‚    â”‚    â””â”€SiLU (2): 3-22                                        [1, 1280, 7, 7]           --                        --\n",
            "â”œâ”€AdaptiveAvgPool2d (avgpool): 1-2                                [1, 1280, 1, 1]           --                        --\n",
            "â”œâ”€Sequential (classifier): 1-3                                    [1, 7]                    --                        True\n",
            "â”‚    â””â”€Dropout (0): 2-10                                          [1, 1280]                 --                        --\n",
            "â”‚    â””â”€Linear (1): 2-11                                           [1, 512]                  655,872                   True\n",
            "â”‚    â””â”€ReLU (2): 2-12                                             [1, 512]                  --                        --\n",
            "â”‚    â””â”€Dropout (3): 2-13                                          [1, 512]                  --                        --\n",
            "â”‚    â””â”€Linear (4): 2-14                                           [1, 7]                    3,591                     True\n",
            "============================================================================================================================================\n",
            "Total params: 4,667,011\n",
            "Trainable params: 4,667,011\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 385.25\n",
            "============================================================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 107.88\n",
            "Params size (MB): 18.67\n",
            "Estimated Total Size (MB): 127.15\n",
            "============================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# í•™ìŠµ ì‹¤í–‰\n",
        "history = trainer.fit(epochs=15, train_dataloader=train_dataloader, val_dataloader=val_dataloader)\n"
      ],
      "metadata": {
        "id": "81dM2kpZXE4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350c70ed-4559-4507-d1fe-a6bec6e22759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë¸ í•™ìŠµ ì‹œì‘!\n",
            "==================================================\n",
            "\n",
            "Epoch 1/15\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Training...]:   0%|          | 0/614 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "[Training...]:   0%|          | 1/614 [00:05<57:11,  5.60s/it]/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
            "  warnings.warn(*args, **kwargs)\n",
            "[Training...]:   1%|â–         | 9/614 [00:39<34:39,  3.44s/it, Train_Loss=1.9, Train_ACC=0.312, Train_AUC=0.534]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™”\n",
        "def plot_training_history(history):\n",
        "  fig, axes = plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "  epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "  # Loss ê·¸ë˜í”„\n",
        "  axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss')\n",
        "  axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss')\n",
        "  axes[0].set_title('Training and Validation Loss')\n",
        "  axes[0].set_xlabel('Epochs')\n",
        "  axes[0].set_ylabel('Loss')\n",
        "  axes[0].legend()\n",
        "  axes[0].grid(True)\n",
        "\n",
        "  # Accuracy ê·¸ë˜í”„\n",
        "  axes[1].plot(epochs, history['train_acc'], 'b-', label='Train Acc')\n",
        "  axes[1].plot(epochs, history['val_acc'], 'r-', label='Val Acc')\n",
        "  axes[1].set_title('Training and Validation Accuracy')\n",
        "  axes[1].set_xlabel('Epochs')\n",
        "  axes[1].set_ylabel('Accuracy')\n",
        "  axes[1].legend()\n",
        "  axes[1].grid(True)\n",
        "\n",
        "  # AUC ê·¸ë˜í”„\n",
        "  axes[2].plot(epochs, history['train_auc'], 'b-', label='Train AUC')\n",
        "  axes[2].plot(epochs, history['val_auc'], 'r-', label='Val AUC')\n",
        "  axes[2].set_title('Training and Validation AUC')\n",
        "  axes[2].set_xlabel('Epochs')\n",
        "  axes[2].set_ylabel('AUC')\n",
        "  axes[2].legend()\n",
        "  axes[2].grid(True)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ì‹¤í–‰\n",
        "plot_training_history(history)\n",
        "\n",
        "# ìµœì¢… ëª¨ë¸ ì €ì¥\n",
        "torch.save(trainer.get_trained_model().state_dict(), 'emotion_classification_model.pth')\n",
        "print(\"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: emotion_classification_model.pth\")"
      ],
      "metadata": {
        "id": "7Ej9nWAKW_0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsYgpIYyW_yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pSSGYTPoXYic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KAUWhLcWXYgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ëª…ìˆ˜\n",
        "ëª¨ë¸ ì˜ˆì¸¡ ë¡œì§ ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "uVFUPs1EXDZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Predictor í´ë˜ìŠ¤ ì •ì˜ ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class EmotionPredictor:\n",
        "    def __init__(self, model_path, device=None):\n",
        "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # ê°ì • ë ˆì´ë¸”\n",
        "        self.emotions = [\"Surprise\", \"Fear\", \"Disgust\", \"Happiness\", \"Sadness\", \"Anger\", \"Neutral\"]\n",
        "\n",
        "        # ëª¨ë¸ êµ¬ì¡° ìƒì„±\n",
        "        classifier_layer = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=1280, out_features=512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(in_features=512, out_features=7)\n",
        "        )\n",
        "        self.model = create_pretrained_model(model_name='efficientnet_b0', classifier_layer=classifier_layer)\n",
        "\n",
        "        # ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        self.transform = test_transform # ì „ì²˜ë¦¬ í™œìš©\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        image_bgr = cv2.imread(image_path)\n",
        "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        transformed = self.transform(image=image_rgb)['image']\n",
        "        input_tensor = transformed.unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(input_tensor)\n",
        "            probs = F.softmax(logits, dim=-1).cpu().numpy()[0] # ëª¨ë“  ê°ì •ì˜ í™•ë¥ ê°’\n",
        "            pred_idx = np.argmax(probs)\n",
        "\n",
        "        return image_rgb, probs, pred_idx"
      ],
      "metadata": {
        "id": "E_T7MnA6XD9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ë¶„ì„ ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜ ì •ì˜ ---\n",
        "def visualize_emotion_analysis(image_path, predictor):\n",
        "    image_rgb, probs, pred_idx = predictor.predict(image_path)\n",
        "\n",
        "    # ì‹œê°í™” ì„¤ì • (1í–‰ 2ì—´)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # 1. ì™¼ìª½: ì´ë¯¸ì§€ ì¶œë ¥\n",
        "    ax1.imshow(image_rgb)\n",
        "    ax1.set_title(f\"Predicted: {predictor.emotions[pred_idx]} ({probs[pred_idx]*100:.2f}%)\",\n",
        "                 fontsize=15, fontweight='bold', pad=20)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # 2. ì˜¤ë¥¸ìª½: ê°ì •ë³„ í™•ë¥  ë§‰ëŒ€ ê·¸ë˜í”„\n",
        "    colors = ['gray'] * 7\n",
        "    colors[pred_idx] = 'royalblue' # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ë§‰ëŒ€ ìƒ‰ìƒ ë³€ê²½\n",
        "\n",
        "    y_pos = np.arange(len(predictor.emotions))\n",
        "    ax2.barh(y_pos, probs * 100, align='center', color=colors)\n",
        "    ax2.set_yticks(y_pos)\n",
        "    ax2.set_yticklabels(predictor.emotions, fontsize=12)\n",
        "    ax2.invert_yaxis()  # ìƒë‹¨ë¶€í„° ë³´ì´ê²Œ ì •ë ¬\n",
        "    ax2.set_xlabel('Probability (%)', fontsize=12)\n",
        "    ax2.set_title('Emotion Probability Distribution', fontsize=15, fontweight='bold', pad=20)\n",
        "    ax2.set_xlim(0, 100)\n",
        "\n",
        "    # í™•ë¥  ìˆ˜ì¹˜ í‘œì‹œ\n",
        "    for i, v in enumerate(probs):\n",
        "        ax2.text(v * 100 + 1, i, f\"{v*100:.1f}%\", color='black', va='center', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ud7vjb1WXEcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUKEW2iuMa5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# test_dfì— labelì´ ìˆëŠ” ê²½ìš° (í˜„ì¬ í´ë” êµ¬ì¡°ìƒ test/1~7ì´ë©´ label ì¡´ì¬)\n",
        "test_dataset = Custom_Dataset(\n",
        "    test_df[\"image_path\"].values,\n",
        "    test_df[\"label\"].values,\n",
        "    transform=test_transform  # ë³´í†µ val/test transform\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "--YPI76RXEXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "idx_to_emotion = {\n",
        "    0: \"surprise\",\n",
        "    1: \"fear\",\n",
        "    2: \"disgust\",\n",
        "    3: \"happiness\",\n",
        "    4: \"sadness\",\n",
        "    5: \"anger\",\n",
        "    6: \"neutral\"\n",
        "}\n",
        "class_names = [idx_to_emotion[i] for i in range(7)]\n",
        "\n",
        "# 1) ì˜ˆì¸¡/ì •ë‹µ ìˆ˜ì§‘\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_dataloader:\n",
        "        x = x.to(device)\n",
        "        logits = model(x)\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        # âœ… (ì¤‘ìš”) ë¼ë²¨ì´ 1~7ì´ë©´ 0~6ìœ¼ë¡œ ë³€í™˜ (í•™ìŠµì—ì„œ labels-1 í–ˆë˜ ê²½ìš°)\n",
        "        y_np = (y.numpy() - 1)\n",
        "\n",
        "        y_true.extend(y_np.tolist())\n",
        "        y_pred.extend(preds.tolist())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# 2) ì „ì²´ ì •í™•ë„\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"\\nâœ… Test Accuracy: {acc*100:.2f}%  ({acc:.4f})\\n\")\n",
        "\n",
        "# 3) ë¶„ë¥˜ ë¦¬í¬íŠ¸ë¥¼ 'í‘œ'ë¡œ ë³´ê¸° ì¢‹ê²Œ\n",
        "report_dict = classification_report(\n",
        "    y_true, y_pred,\n",
        "    target_names=class_names,\n",
        "    digits=4,\n",
        "    output_dict=True,\n",
        "    zero_division=0\n",
        ")\n",
        "\n",
        "# í´ë˜ìŠ¤ í–‰ë§Œ ë½‘ì•„ì„œ í‘œë¡œ ì •ë¦¬\n",
        "rows = []\n",
        "for name in class_names:\n",
        "    rows.append([name,\n",
        "                 report_dict[name][\"precision\"],\n",
        "                 report_dict[name][\"recall\"],\n",
        "                 report_dict[name][\"f1-score\"],\n",
        "                 int(report_dict[name][\"support\"])])\n",
        "\n",
        "report_df = pd.DataFrame(rows, columns=[\"class\", \"precision\", \"recall\", \"f1\", \"support\"])\n",
        "report_df_sorted = report_df.sort_values(\"f1\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"ğŸ“Œ Class-wise metrics (sorted by F1):\")\n",
        "display(report_df_sorted)\n",
        "\n",
        "# 4) ì˜ˆì¸¡ ë¶„í¬ / ì •ë‹µ ë¶„í¬ (í¸í–¥ ì§ê´€ í™•ì¸)\n",
        "true_counts = np.bincount(y_true, minlength=7)\n",
        "pred_counts = np.bincount(y_pred, minlength=7)\n",
        "\n",
        "dist_df = pd.DataFrame({\n",
        "    \"class\": class_names,\n",
        "    \"true_count\": true_counts,\n",
        "    \"pred_count\": pred_counts\n",
        "})\n",
        "print(\"\\nğŸ“Œ Class distribution (true vs pred):\")\n",
        "display(dist_df)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar(dist_df[\"class\"], dist_df[\"true_count\"])\n",
        "plt.title(\"True label distribution (Test)\")\n",
        "plt.xticks(rotation=30, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar(dist_df[\"class\"], dist_df[\"pred_count\"])\n",
        "plt.title(\"Predicted label distribution (Model output)\")\n",
        "plt.xticks(rotation=30, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5) í˜¼ë™í–‰ë ¬ì„ 'í‘œ'ë¡œ + íˆíŠ¸ë§µ(ìˆ˜ì¹˜/ë¹„ìœ¨ ë‘˜ ë‹¤)\n",
        "cm = confusion_matrix(y_true, y_pred, labels=np.arange(7))\n",
        "cm_df = pd.DataFrame(cm, index=[f\"true_{c}\" for c in class_names],\n",
        "                        columns=[f\"pred_{c}\" for c in class_names])\n",
        "\n",
        "print(\"\\nğŸ“Œ Confusion Matrix (counts):\")\n",
        "display(cm_df)\n",
        "\n",
        "# ë¹„ìœ¨(í–‰ ê¸°ì¤€) = ê° true í´ë˜ìŠ¤ì—ì„œ ì–´ë””ë¡œ ê°”ëŠ”ì§€ %\n",
        "cm_row_sum = cm.sum(axis=1, keepdims=True)\n",
        "cm_norm = np.divide(cm, cm_row_sum, out=np.zeros_like(cm, dtype=float), where=cm_row_sum!=0)\n",
        "cm_norm_df = pd.DataFrame(cm_norm, index=[f\"true_{c}\" for c in class_names],\n",
        "                             columns=[f\"pred_{c}\" for c in class_names])\n",
        "\n",
        "print(\"\\nğŸ“Œ Confusion Matrix (row-normalized, %):\")\n",
        "display((cm_norm_df*100).round(1))\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cm, aspect=\"auto\")\n",
        "plt.title(\"Confusion Matrix (Counts)\")\n",
        "plt.xticks(np.arange(7), class_names, rotation=30, ha=\"right\")\n",
        "plt.yticks(np.arange(7), class_names)\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cm_norm, aspect=\"auto\")\n",
        "plt.title(\"Confusion Matrix (Row-normalized)\")\n",
        "plt.xticks(np.arange(7), class_names, rotation=30, ha=\"right\")\n",
        "plt.yticks(np.arange(7), class_names)\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6) ê°€ì¥ ë§ì´ í—·ê°ˆë¦° TOP ì˜¤ë¶„ë¥˜ ìŒ ì¶œë ¥ (ì§ê´€ì ìœ¼ë¡œ â€œì–´ë””ê°€ ë¬¸ì œì¸ì§€â€)\n",
        "pairs = []\n",
        "for i in range(7):\n",
        "    for j in range(7):\n",
        "        if i == j:\n",
        "            continue\n",
        "        pairs.append((cm[i, j], class_names[i], class_names[j]))\n",
        "\n",
        "pairs.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "print(\"\\nğŸ”¥ Top-10 confusions (true -> pred):\")\n",
        "for k in range(10):\n",
        "    cnt, t, p = pairs[k]\n",
        "    print(f\"{k+1:2d}) {t:10s} -> {p:10s} : {cnt}\")\n"
      ],
      "metadata": {
        "id": "FGx_bh1rXY43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ---\n",
        "from google.colab import files\n",
        "\n",
        "# 1. ëª¨ë¸ ê°ì²´ ìƒì„±\n",
        "predictor = EmotionPredictor(model_path='emotion_classification_model.pth')\n",
        "\n",
        "# 2. í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ì—…ë¡œë“œ\n",
        "print(\"ë¶„ì„í•  ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš” (jpg, png ë“±)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 3. ëª¨ë“  ì—…ë¡œë“œ íŒŒì¼ì— ëŒ€í•´ ì‹œê°í™” ì‹¤í–‰\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\n[ {filename} ë¶„ì„ ê²°ê³¼ ]\")\n",
        "    visualize_emotion_analysis(filename, predictor)"
      ],
      "metadata": {
        "id": "pD0n-JiOXZK6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}